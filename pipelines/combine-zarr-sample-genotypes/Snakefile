import pandas as pd
import os
import pyfaidx

fa = pyfaidx.Fasta(config["fasta_path"])
contigs = list(fa.keys())

fofn_path = config["fofn"]
sampleset = os.path.basename(os.path.dirname(fofn_path))
fofn = pd.read_csv(config["fofn"], sep="\t")
samples = fofn["sample"].unique()

if "contigs" not in config:
  config["contigs"] = list(fa.keys())


rule all_merge:
  input:
    expand(
      os.path.join("{sampleset}/callset.zarr/{chrom}/calldata/{field}"),
      sampleset=[sampleset],
      field=config["fields"],
      chrom=config["contigs"]),
    os.path.join(sampleset, "merge_genotypes_config.yml")


rule all_freqs:
  input:
    expand(
      os.path.join("{sampleset}/allele_frequencies.zarr/{chrom}/AF"),
      chrom=contigs,
      sampleset=[sampleset]),
    os.path.join(sampleset, "merge_genotypes_config.yml")


rule merge_zarr:
  input:
    manifest="{sampleset}/manifest"
  output:
    zarr=directory("{sampleset}/callset.zarr/{chrom}/calldata/{field}"),
    done=touch("{sampleset}/callset.zarr/{chrom}/calldata/{field}.complete")
  params:
    samples=lambda y: os.path.join(y.sampleset, "manifest"),
    input_pattern=lambda y: os.path.join(config["data_dir"], "{sample}" + config["gt_suffix"]),
    output=lambda y: os.path.join(y.sampleset, "callset.zarr"),
    seqid=lambda y: y.chrom,
    field=lambda y: y.field,
    cname="zstd",
    clevel=1,
    chunk_width=config["chunk_width"],
    shuffle=0,
    num_workers=4,
    req="h_vmem=4G",
    pe="-pe simple_pe 4"
  conda:
    "env.yml"
  script:
    "../../scripts/combine_zarr.py"


rule compute_geno_freqs:
  output:
    zarr=directory("{sampleset}/allele_frequencies.zarr/{chrom}/AF"),
    done=touch("{sampleset}/allele_frequencies.zarr/{chrom}/AF.complete"),
  input:
    zarr="{sampleset}/callset.zarr/{chrom}/calldata/GT",
    sites=config["sites_path"]
  params:
    outz=lambda y: os.path.join(y.sampleset, "allele_frequencies.zarr"),
    inz=lambda y: os.path.join(y.sampleset, "callset.zarr"),
    req="h_vmem=10G",
    pe=""
  run:
    import zarr
    import allel
    import numpy as np
    from pathlib import Path
    
    callset_fn = params.inz
    output_fn = params.outz
    chrom = wildcards.chrom
    
    zh = zarr.open_group(output_fn, "a")
    merged_callset = zarr.open_group(callset_fn, "r")

    if Path(input.sites).is_file():
      store = zarr.ZipStore(input.sites, mode='r')
      zsites = zarr.Group(store)

    else:
      zsites = zarr.open_group(input.sites, "r")
    
    gt = allel.GenotypeChunkedArray(merged_callset[chrom]["calldata/GT"])
    positions = zsites[chrom]["variants/POS"]

    if not np.any(gt.is_called()):
      ac = np.zeros((positions.shape[0], 4), dtype="int")
      af = np.zeros((positions.shape[0], 4))
    else:
      ac = gt.count_alleles(max_allele=3)
      af = ac.to_frequencies()    

    zch = zh.require_group(chrom)
    
    zch.create_dataset("POS", data=positions)
    zch.create_dataset("AF", data=af)
    zch.create_dataset("AC", data=ac)


rule dump_manifest:
  output:
    txt="{sampleset}/manifest"
  params:
    req="h_vmem=4G",
  run:
    with open(output.txt, mode="w") as wr:
      print("sample_name", file=wr)
      print("\n".join(samples), file=wr)


rule write_config:
  output:
    cfg="{sampleset}/merge_genotypes_config.yml"
  params:
    req="h_vmem=2G"
  run:
    import yaml
    with open(output.cfg, "w") as fh:
      yaml.dump(config, fh)

