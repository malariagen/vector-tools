import os
import pandas as pd
from itertools import combinations

with open(config["fofns"], "r") as fh:
  fofns = [x.strip() for x in fh.readlines()]

# input is a set of fofns
all_fofns = pd.concat([pd.read_csv(f, sep="\t") for f in fofns])
samples = sorted(all_fofns["sample"].unique())

# HACK
print("WARNING HACK IN OPERATION: IGNORING NON EXISTENT FILES")
paths = [os.path.join(config["input_location"], s + config["gt_suffix"]) for s in samples]
samples = [s for (s, p) in zip(samples, paths) if os.path.isfile(p)][:5]
# END HACK


rule determine_pwc:
  input:
    pwdf=["pwd/{sampleA}.{sampleB}.txt".format(sampleA=a, sampleB=b) for a, b in combinations(samples, 2)],
    fofn=fofns
    

rule compute_sample_pwd:
  input:
    genotA="{samplesetA}/callset.zarr",
    genotB="{samplesetB}/callset.zarr",
    biallelic=config["biallelic_sites"],
    sites=config["genotyped_sites"]
  output:
    zarr="pwd/{samplesetA}.{samplesetB}.zarr"
  run:
    import allel
    import zarr
    import numpy as np
    import scipy.spatial.distance as dist
    
    calldataA = zarr.open_group(input.genotA)
    calldataB = zarr.open_group(input.genotB)
	
    biallelic_sites = zarr.open_group(input.biallelic, mode="r")
    called_sites = zarr.open_group(input.sites, mode="r")

    # create output file
    samples_a = calldataA["samples"][:]
    samples_b = calldataB["samples"][:]

    euc_d = np.zeros(
      (len(config["pwd_contigs"]), samples_a.size, samples_b.size), dtype="float")

    cit_d = np.zeros(
      (len(config["pwd_contigs"]), samples_a.size, samples_b.size), dtype="float")

    nsites = np.zeros(
      (len(config["pwd_contigs"]), samples_a.size, samples_b.size), dtype="float")

    for cix, contig in enumerate(config["pwd_contigs"]):

      sites_pos = allel.SortedIndex(called_sites[contig]["variants/POS"])
      bial_pos = allel.SortedIndex(biallelic_sites[contig]["variants/POS"])
      loc = sites_pos.locate_keys(bial_pos)

      bref = np.array(biallelic_sites[contig]["variants/REF"])
      balt = np.array(biallelic_sites[contig]["variants/ALT"])
      alleles=np.hstack([bref[:, np.newaxis], balt])

      # reduce to biallelic sites all samples still
      gt_a = allel.GenotypeDaskArray(calldataA[contig]["calldata/GT"]).compress(loc)
      gt_b = allel.GenotypeDaskArray(calldataB[contig]["calldata/GT"]).compress(loc)

      mapping = allel.create_allele_mapping(
        ref=np.compress(loc, called_sites[contig]["variants/REF"]),
        alt=np.compress(loc, called_sites[contig]["variants/ALT"]),
        alleles=alleles)

      gt_a_map = gt_a.map_alleles(mapping)
      gt_b_map = gt_b.map_alleles(mapping)

      # now we can loop through sample pairs:
      for i, j in product(range(samples_a.size), range(samples_b.size)):

        print(contig, i, j)
        sa = gt_a_map.take([i], axis=1)
        sb = gt_b_map.take([j], axis=1)

        not_missing = (sa.count_missing(axis=1) == 0) & (sa.count_missing(axis=1) == 0)

        _xa = sa.compress(not_missing, axis=0).to_n_alt()
        _xb = sb.compress(not_missing, axis=0).to_n_alt()

        euc_d[cix, i, j] = dist.euclidean(_xa, _xb)
        cit_d[cix, i, j] = dist.cityblock(_xa, _xb)
        nsites[cix, i, j] = _xa.shape[0]

    zz = zarr.open_group(output.zarr, "w")
    zz.create_dataset("euclidean", data=euc_d)
    zz.create_dataset("cityblock", data=cit_d)
    zz.create_dataset("comp_sites", data=nsites)

    with open(output.txt, "w") as wr:
      print("EUC", deuc, file=wr)
      print("CIB", dcit, file=wr)
      print("nSI", xa.shape[0], file=wr)
