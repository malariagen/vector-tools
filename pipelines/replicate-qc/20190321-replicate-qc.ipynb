{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate QC\n",
    "\n",
    "This notebook takes a merged sampleset, ie all GT arrays from a set that have been merged by the `combine-zarr-callset` pipeline, and computes pairwise distances between them.\n",
    "\n",
    "Each contig is handled separately, and the dimensions of the resulting outputs are: contigs x npairs.\n",
    "\n",
    "Three arrays are written, one with euclidean distance, one with cityblock distance and one with the number of comparable (ie called) sites.\n",
    "\n",
    "NB: We restrict to bialleleic positions in phase 2. \n",
    "\n",
    "NB: Efficiency could be improved markedly by chunking the genotypes with (X, 1, 2), to make it more efficient at reading in the relevant data. \n",
    "(I'm currently recreating on the cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import allel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask-distance in /opt/conda/lib/python3.6/site-packages (0.2.0)\n",
      "Requirement already satisfied: dask in /opt/conda/lib/python3.6/site-packages (from dask-distance) (1.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from dask-distance) (1.15.4)\n",
      "\u001b[33mYou are using pip version 19.0, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dask-distance\n",
    "import dask_distance as dist\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleset = \"AG1000G-UG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "calldata = zarr.open_group(\"/gcs/observatory/callset.zarr\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/gcs/observatory/manifest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume this is ok for now. Normally use the manifest\n",
    "samples = df[\"sample_name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38439b8c84534f48ad7755c3a792f20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=40)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.8.71.16:34861\n",
       "  <li><b>Dashboard: </b><a href='/user/nicholasharding/proxy/8787/status' target='_blank'>/user/nicholasharding/proxy/8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.8.71.16:34861' processes=0 cores=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_callset = zarr.open_group(\"/gcs/phase2/AR1/variation/main/zarr2/ag1000g.phase2.ar1\")\n",
    "called_sites = zarr.open_group(\"/gcs/observatory/ag.allsites.nonN.zarr.zip\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find biallelic sites\n",
    "def find_phase2_bialleleic_sites(chrom):\n",
    "\n",
    "    g = allel.GenotypeDaskArray(phase2_callset[chrom][\"calldata\"][\"genotype\"])\n",
    "    biallelic = (g.max(axis=[1,2]) <= 1).compute()\n",
    "                 \n",
    "    d = {}\n",
    "    for x in \"POS\", \"REF\", \"ALT\":\n",
    "        v = phase2_callset[chrom][\"variants\"][x]\n",
    "        dav = da.from_zarr(v, chunksize=v.chunks)\n",
    "        d[x] = da.compress(biallelic, dav, axis=0)\n",
    "        \n",
    "    return d[\"POS\"], d[\"ALT\"], d[\"REF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"pwd_contigs\": [\"3L\", \"3R\", \"2L\", \"2R\", \"X\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130321"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(combinations(range(len(samples)), 2))\n",
    "npairs = len(pairs)\n",
    "dist_e = np.zeros((len(config[\"pwd_contigs\"]), npairs))\n",
    "dist_c = np.zeros((len(config[\"pwd_contigs\"]), npairs))\n",
    "numb_s = np.zeros((len(config[\"pwd_contigs\"]), npairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compressing\n",
      "mapped ok\n"
     ]
    }
   ],
   "source": [
    "for cix, contig in enumerate(config[\"pwd_contigs\"]):\n",
    "\n",
    "    sites_pos = allel.SortedIndex(called_sites[contig][\"variants/POS\"])\n",
    "    bial_pos, bial_alt, bial_ref = find_phase2_bialleleic_sites(contig)\n",
    "    loc = sites_pos.locate_keys(bial_pos)\n",
    "    \n",
    "    alleles=da.hstack((bial_ref.reshape((-1, 1)), bial_alt))\n",
    "\n",
    "    # reduce to biallelic sites all samples still\n",
    "    print(\"compressing\")\n",
    "    gt_a = allel.GenotypeDaskArray(calldata[contig][\"calldata/GT\"]).compress(loc)\n",
    "\n",
    "    mapping = allel.create_allele_mapping(\n",
    "        ref=np.compress(loc, called_sites[contig][\"variants/REF\"]),\n",
    "        alt=np.compress(loc, called_sites[contig][\"variants/ALT\"]),\n",
    "        alleles=alleles)\n",
    "    \n",
    "    print(\"mapped ok\")\n",
    "    remap = gt_a.map_alleles(mapping)\n",
    "    count_alts = remap.to_n_alt()\n",
    "    is_called = remap.is_called()\n",
    "    \n",
    "    for i, j in pairs:\n",
    "        ix = allel.condensed_coords(i, j, len(samples))\n",
    "        nmloc = (is_called[:, i] & is_called[:, j]).compute()\n",
    "\n",
    "        x1 = da.compress(nmloc, count_alts[:, i], axis=0)\n",
    "        x2 = da.compress(nmloc, count_alts[:, j], axis=0)\n",
    "            \n",
    "        dist_e[cix, ix] = dist.euclidean(x1, x2)\n",
    "        dist_c[cix, ix] = dist.cityblock(x1, x2)\n",
    "        numb_s[cix, ix] = x1.shape[0]\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    'pwdist_{sampleset}'.format(sampleset=sampleset), \n",
    "    euclidean=dist_e, \n",
    "    cityblock=dist_c, \n",
    "    number_sites=numb_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
